<!DOCTYPE html>
<html>

<head>
  <link rel="stylesheet" type="text/css" href="style.css">
  <link href='https://fonts.googleapis.com/css?family=Roboto:300,400,500' rel='stylesheet' type='text/css'>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" href="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
  <script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>


</head>

<body style="font-family: 'Roboto', sans-serif; font-weight: 300; font-size: 16px">
<div>
  <table width="100%" height=150px background="http://www.image-sensors.com/ImageSensors/media/Image-Sensors-2015/News%20article%20image/Am_image.png">
    <tr>
      <td valign="center" id="header" style="font-size: 48px">
        Introduction to Computer Vision
      </td>
    </tr>
  </table>
</div>


      
<!-- Fixed navigation bar -->
<div>
<nav class="navbar navbar-default">
  <div class="container-fluid">
    <ul class="nav navbar-nav">
      <li><a href="index.html">Home</a></li>
      <li class="active"><a href="applications.html">Applications</a></li>
      <li><a href="tutorials.html">Tutorials</a></li>
      <li><a href="resources.html">Resources</a></li>
      <li><a href="about.html">About</a></li>
    </ul>
  </div>
</nav>
</div>

<body>

<div id="content">

  <div class="section-title">Applications</div>

    <div class="section-text">

      <p style="font-weight: 500">Singular Value Decomposition (SVD):</p>
      <p>Often times, raw data sets are redundant and have patterns. Thus, a more efficient representation of the data would be useful. One way to do this is SVD. SVD is an algorithm that factors any matrix A into three matrices U&#931;V<sup>T</sup>, where U and V are rotation matrices and &#931; is a scaling matrix. One of its applications is image compression. SVD of an image matrix produces components of the final image.</p>

      <figure>
        <img src="ApplicationsPictures/svd1.png" alt="SVD" style="width:175px;height:150px"/>
        <img src="ApplicationsPictures/svd2.png" alt="SVD" style="width:175px;height:150px"/>
        <figcaption>Only the first 10 out of 300 principal components of this image are used to compress it.</figcaption>
      </figure>
      <p></p>

      <p>As a result, the minimal representation of images and data samples by including only its major patterns with this technique, known as Principal Component Analysis, increases the speed of machine learning algorithms significantly. To learn more about PCA and how it can be used for face detection, click <a href="tutorial4.html">here</a>.</p>
      <br></br>

      <p style="font-weight: 500">Filters</p>
      <p>We have all heard of image filters in applications like Instagram. Well, computer vision is used to create the enhancing effects! Different filters produce different effects. For example, the moving average filter smoothes an image, while other manipulations can sharpen or denoise an image. To learn more about systems and filters, click <a href="tutorial1.html">here</a>.</p>

      <figure>
        <img src="ApplicationsPictures/filters.jpg" alt="Filters" style="width:236;height:236"/>
      </figure>
      <br></br>

      <p style="font-weight: 500">Object Recognition</p>
      <p>We often oversee the huge role object recognition plays in our daily lives. Animals rely on it to survive, and it is essential for us as well. One way to locate and identify objects with computer vision is through edge detection. Once we have the intensity profile of an image, we can take its first derivative to pinpoint where edges occur and extract valuable information about the image. For more information about object recognition, click <a href="tutorial4.html">here</a>.</p>

      <figure>
        <img src="ApplicationsPictures/objectrecognition.jpg" alt="Object Recognition" style="width:630px;height:266px"/>
      </figure>
      <br></br>

      <p style="font-weight: 500">Image Matching</p>
      <p>Image matching has several applications, such as panorama stitching. To effectively align the photos, keypoints are identified, a region around each keypoint is defined and normalized, and a local descriptor is computed from the extracted region. The local descriptors are then matched to stitch images together. Keypoint detection can also be used to recognize specific objects and scenes. To learn more about key points and different detection algorithms, click <a href="tutorial2.html">here</a>.</p>

      <figure>
        <img src="ApplicationsPictures/pano.jpg" alt="Image Matching" style="width:623pxpx;height:128px"/>
      </figure>
      <br></br>

      <p style="font-weight: 500">Segmentation</p>
      <p>Sometimes, it can be hard to analyze the raw pixels of an image. This is when segmentation comes in handy. Image segmentation is the clustering of pixels into regions based on surfaces, objects, or parts of objects. The divided regions are then represented as a single entity, simplifying the image without losing content. Parts of an image can also be taken and put onto another image. For more information on segmentation, clustering, and some common algorithms used to perform this, click <a href="tutorial3.html">here</a>.</p>

      <figure>
        <img src="ApplicationsPictures/segmentation.png" alt="Segmentation" style="width:300px;height:200px"/>
      </figure>
      <br></br>

      <p style="font-weight: 500">Optical Flow</p>
      <p>A video consists of bunch of images captured over time. Optical flow is the pattern of motion of the objects, surfaces, or contours in a scene. The estimation of optical flow between frames can give the velocities of the various elements in the video and be used to track visual features over the video frames.</p>

      <figure>
        <img src="ApplicationsPictures/opticalflow.png" alt="Segmentation" style="width:572px;height:225px"/>
      </figure>

    </div>

</div>

</body>

</html>